{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "de711a5e-c0a1-496d-bc42-9bd82eb7d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as ns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7ba34606-577c-4551-8638-b47a6a2f2029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    \n",
    "    def __init__(self, X, y, learningRate = 0.00001, tolerance = 0.00005,maxIteration = 5000 ):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.tolerance = tolerance\n",
    "        self.maxIteration = maxIteration\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        \n",
    "    \n",
    "    def addX0(self):\n",
    "        return np.column_stack([np.ones([X.shape[0],1]), X])\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        sig= 1 / (1+ np.exp(-z))\n",
    "        return sig\n",
    "    \n",
    "    def costFunction (self, X, y):\n",
    "        pred_ = np.log(np.ones(X.shape[0]) + np.exp(X.dot(self.w))) - X.dot(self.w).dot(y)\n",
    "        cost = pred_.sum()\n",
    "        return cost\n",
    "    \n",
    "    def gradient(self, X, y):\n",
    "        sigmoid = self.sigmoid(X.dot(self.w))\n",
    "        grad = (sigmoid - y).dot(X)\n",
    "        return grad\n",
    "    \n",
    "    def gradientDescent(self, X, y):\n",
    "        \n",
    "        errors= []\n",
    "        last = float('inf')\n",
    "        \n",
    "        for i in tqdm(range(self.maxIteration)):\n",
    "            self.w = self.w - self.learningRate * self.gradient(X, y)\n",
    "            curr = self.costFunction(X, y)\n",
    "            \n",
    "            diff = last - curr\n",
    "            last = curr\n",
    "            \n",
    "            errors.append(curr)\n",
    "            \n",
    "#             if diff < self.tolerance:\n",
    "#                 print(\" The model has stopped learning\")\n",
    "#                 break\n",
    "                \n",
    "        #self.plot_cost(errors)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = self.sigmoid(X.dot(self.w))\n",
    "        return np.around(pred)\n",
    "        \n",
    "    def evaluate(self, y, y_hat):\n",
    "            \n",
    "        y = (y == 1)\n",
    "        y_hat= (y_hat == 1)\n",
    "            \n",
    "        accuracy = (y == y_hat).sum() / y.size\n",
    "        precision = (y & y_hat).sum() / y_hat.sum()\n",
    "        recall = (y & y_hat).sum() / y.sum()\n",
    "        print('accuracy was:' +str(accuracy) )\n",
    "        print('precision was:' +str(precision) )\n",
    "        print('recall was:' +str(recall) )\n",
    "        return recall, precision, accuracy\n",
    "        \n",
    "    def fit(self):\n",
    "#         self.X_train, self.X_test. self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.3)\n",
    "            \n",
    "        self.w = np.ones(self.X_train.shape[1], dtype = np.float64) * 0\n",
    "        self.gradientDescent(self.X_train, self.y_train)\n",
    "            \n",
    "        print(self.w)\n",
    "            \n",
    "        y_hat_train = self.predict(self.X_train)\n",
    "        recall, precision, accuracy = self.evaluate(self.y_train, y_hat_train)\n",
    "            \n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "        # Data for three-dimensional scattered points\n",
    "        ax.scatter3D(self.X_train[:, 0], self.X_train[:, 1], \n",
    "        self.sigmoid(self.X_train.dot(self.w)), \n",
    "        c = self.y_train[:], cmap='viridis', s=100);\n",
    "\n",
    "        ax.set_xlim3d(55, 80)\n",
    "        ax.set_ylim3d(80, 240)\n",
    "        plt.xlabel('$x_1$ feature', fontsize=15)\n",
    "        plt.ylabel('$x_2$ feature', fontsize=15, )\n",
    "        ax.set_zlabel('$P(Y = 1|x_1, x_2)$', fontsize=15, rotation = 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    def scatterPlt(self):\n",
    "        # evenly sampled points\n",
    "        x_min, x_max = 55, 80\n",
    "        y_min, y_max = 80, 240\n",
    "\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 250),\n",
    "                                 np.linspace(y_min, y_max, 250))\n",
    "        grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "        probs = grid.dot(self.w).reshape(xx.shape)\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(14,12))\n",
    "\n",
    "\n",
    "        ax.contour(xx, yy, probs, levels=[0.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
    "\n",
    "\n",
    "        ax.scatter(self.X_train[:, 0], self.X_train[:, 1], \n",
    "                   c=self.y_train[:], s=50,\n",
    "                   cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "                   edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "        plt.xlabel('x1 feature')\n",
    "        plt.ylabel('x2 feature')\n",
    "\n",
    "\n",
    "    def plot3D(self):\n",
    "        # evenly sampled points\n",
    "        x_min, x_max = 55, 80\n",
    "        y_min, y_max = 80, 240\n",
    "\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 250),\n",
    "                             np.linspace(y_min, y_max, 250))\n",
    "\n",
    "        grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "        probs = grid.dot(self.w).reshape(xx.shape)\n",
    "        fig = plt.figure(figsize=(14,12))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.contour3D(xx, yy, probs, 50, cmap='binary')\n",
    "\n",
    "        ax.scatter3D(self.X_train[:, 0], self.X_train[:, 1], \n",
    "                   c=self.y_train[:], s=50,\n",
    "                   cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "                   edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "        ax.set_xlabel('x1')\n",
    "        ax.set_ylabel('x2')\n",
    "        ax.set_zlabel('probs')\n",
    "        ax.set_title('3D contour')\n",
    "        plt.show()\n",
    "            \n",
    "         \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "78465a18-726e-409f-87b2-2e142b2576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('Lab3_data.xls', sheet_name = '2004--2005 Data' ) \n",
    "test_df = pd.read_excel('Lab3_data.xls', sheet_name = '2004--2007 Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "799447ef-7a8d-465c-b62d-ff09a8bdbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb28005-148c-4539-b4a6-0cb06ddb3f1b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "de916532-7f2e-4137-a46c-7d355972847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train= train_df[:, 1:], train_df[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "76ddb242-9579-4cd5-b9df-9d9c1b1ae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Logistic_Regression(X_train, y_train, tolerance= 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "95204a55-c778-4dd6-8313-edf65c103652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 36484.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47599252  0.23073142]\n",
      "accuracy was:0.9565217391304348\n",
      "precision was:0.9722222222222222\n",
      "recall was:0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99b7f5-9f0d-4d5b-ba48-1eadc8d36f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbc050-1de2-4b69-a5ee-18b2043e23a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
